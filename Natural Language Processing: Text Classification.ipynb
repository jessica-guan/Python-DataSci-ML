{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessica-guan/Python-DataSci-ML/blob/main/Natural%20Language%20Processing%3A%20Text%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 22: Natural Language Processing Review**\n",
        "---\n",
        "\n",
        "### **Description**\n",
        "In today's lab, we will review everything we have learned about implementing a neural network for NLP tasks including text classification.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Lab Structure**\n",
        "\n",
        "**Part 1**: [Text Classification of Hotel Reviews](#p1)\n",
        "\n",
        "**Part 2**: [Convolutional Neural Networks](#p2)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Goals**\n",
        "By the end of this lab, you will:\n",
        "* Understand how to apply vectorization and embedding layers in models.\n",
        "* Compare a fully connected network to a CNN for text classification with embeddings.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Cheat Sheets**\n",
        "[Natural Language Processing II](https://docs.google.com/document/d/1p3xVUL1F6SEkusCI4klPLYqQwCkVN5s00ZvJjBpiSqM/edit?usp=sharing)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Before starting, run the code below to import all necessary functions and libraries.**"
      ],
      "metadata": {
        "id": "IXQOERy_lfVd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNXc7I_uIP5U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from random import choices\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"p1\"></a>\n",
        "\n",
        "---\n",
        "## **Part 1: Text Classification of Hotel Reviews**\n",
        "---\n",
        "\n",
        "In this part we will focus on building a model using a TripAdvisor dataset containing hotel reviews. This is a dataset of 20,000 hotel reviews including the `Review` and a `Rating` on a scale of 1-5.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "**Run the code provided below to import the dataset.**"
      ],
      "metadata": {
        "id": "2fndaCy_mQ_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/the-codingschool/TRAIN-datasets/main/tripadvisor_reviews/tripadvisor_hotel_reviews.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.head()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[\"Review\"], df[\"Rating\"], test_size = 0.2, random_state = 42)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "y_train = to_categorical(y_train - 1, num_classes=5)\n",
        "y_test = to_categorical(y_test - 1, num_classes=5)"
      ],
      "metadata": {
        "id": "ACX4sfJW0bq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Problem #1.1: Create the `TextVectorization` layer**\n",
        "\n",
        "\n",
        "To get started, let's create a `TextVectorization` layer to vectorize this data.\n",
        "\n",
        "Specifically,\n",
        "1. Initialize the layer with the specified parameters.\n",
        "\n",
        "2. Adapt the layer to the training data.\n",
        "\n",
        "3. Look at the newly built vocabulary."
      ],
      "metadata": {
        "id": "HuGSwhDc0e1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Initialize the layer with the specified parameters.**\n",
        "\n",
        "* The vocabulary should be at most 5000 words.\n",
        "* The layer's output should always be 64 integers."
      ],
      "metadata": {
        "id": "JlbOhj9L0hdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens = 5000,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = 64\n",
        "  )"
      ],
      "metadata": {
        "id": "r4CA7F9W0l4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Adapt the layer to the training data.**"
      ],
      "metadata": {
        "id": "3SgPJHmy0plM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.adapt(x_train)"
      ],
      "metadata": {
        "id": "sGMMXLG50ruI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Look at the newly built vocabulary.**"
      ],
      "metadata": {
        "id": "7KWwtA--0ue-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.get_vocabulary()[:50]"
      ],
      "metadata": {
        "id": "t_7qWqMl0xAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1f9281-72ac-4847-ab4a-c8f9f3d9b9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'hotel',\n",
              " 'room',\n",
              " 'not',\n",
              " 'great',\n",
              " 'nt',\n",
              " 'good',\n",
              " 'staff',\n",
              " 'stay',\n",
              " 'did',\n",
              " 'just',\n",
              " 'nice',\n",
              " 'rooms',\n",
              " 'no',\n",
              " 'location',\n",
              " 'stayed',\n",
              " 'service',\n",
              " 'time',\n",
              " 'night',\n",
              " 'beach',\n",
              " 'clean',\n",
              " 'day',\n",
              " 'breakfast',\n",
              " 'food',\n",
              " 'like',\n",
              " 'really',\n",
              " 'resort',\n",
              " 'place',\n",
              " 'pool',\n",
              " 'people',\n",
              " 'friendly',\n",
              " 'small',\n",
              " 'little',\n",
              " 'got',\n",
              " 'walk',\n",
              " 'excellent',\n",
              " 'area',\n",
              " '2',\n",
              " 'best',\n",
              " 'helpful',\n",
              " 'restaurant',\n",
              " 'bar',\n",
              " 'bathroom',\n",
              " 'bed',\n",
              " 'restaurants',\n",
              " 'water',\n",
              " 'recommend',\n",
              " 'trip',\n",
              " 'went']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Problem #1.2: Build and Train a Dense model**\n",
        "\n",
        "Complete the code below to build a model with the following layers.\n",
        "\n",
        "An Embedding layer such that:\n",
        "- The vocabulary contains 5000 tokens.\n",
        "- The input length corresponds to the output of the vectorization layer.\n",
        "- The number of outputs per input is 128.\n",
        "\n",
        "<br>\n",
        "\n",
        "Hidden layers such that:\n",
        "\n",
        "- There's at least one Dense layer.\n",
        "\n",
        "<br>\n",
        "\n",
        "A Dense layer for outputting classification probabilities for each of the possible ratings (1-5)."
      ],
      "metadata": {
        "id": "XH9dVdBW1D4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Input, Vectorization, and Embedding Layers\n",
        "model.add(Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vectorize_layer)\n",
        "model.add(Embedding(input_dim=5000, output_dim=128))\n",
        "\n",
        "# Hidden Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Printing Structure\n",
        "for layer in model.layers:\n",
        "  print(str(layer.input_shape) + \" -> \" + str(layer.output_shape))\n",
        "print(\"\\n\\n\\n\")"
      ],
      "metadata": {
        "id": "JkZEoo3Up_LN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6250234-0665-4734-b345-6aec02996ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1) -> (None, 64)\n",
            "(None, 64) -> (None, 64, 128)\n",
            "(None, 64, 128) -> (None, 8192)\n",
            "(None, 8192) -> (None, 64)\n",
            "(None, 64) -> (None, 5)\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting\n",
        "opt = Adam(learning_rate = 0.01)\n",
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=200, epochs=5)\n",
        "\n",
        "# Evaluating\n",
        "print(\"\\n\\n\\n\")\n",
        "model.evaluate(x_train, y_train)\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "uLOhGhjhpGA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4207ba39-6d99-4501-eb0e-11aca4d4aac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "82/82 [==============================] - 6s 63ms/step - loss: 0.9779 - accuracy: 0.5747\n",
            "Epoch 2/5\n",
            "82/82 [==============================] - 4s 46ms/step - loss: 0.4147 - accuracy: 0.8361\n",
            "Epoch 3/5\n",
            "82/82 [==============================] - 4s 52ms/step - loss: 0.1493 - accuracy: 0.9472\n",
            "Epoch 4/5\n",
            "82/82 [==============================] - 3s 42ms/step - loss: 0.0533 - accuracy: 0.9815\n",
            "Epoch 5/5\n",
            "82/82 [==============================] - 4s 43ms/step - loss: 0.0344 - accuracy: 0.9898\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.0171 - accuracy: 0.9938\n",
            "129/129 [==============================] - 1s 4ms/step - loss: 3.0836 - accuracy: 0.5667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.0836269855499268, 0.5667235851287842]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"p2\"></a>\n",
        "\n",
        "---\n",
        "## **Part 2: Convolutional Neural Networks**\n",
        "---\n",
        "\n",
        "Complete the code below to train a new model that is identical to the one above, except using any or all of the CNN layers that keras provides. The goal is to create a model that performs as well as possible on the *test set*.\n",
        "**Which architecture performs better?**"
      ],
      "metadata": {
        "id": "sAle50ovow1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Input, Vectorization, and Embedding Layers\n",
        "model.add(Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vectorize_layer)\n",
        "model.add(Embedding(input_dim=5000, output_dim=128))\n",
        "\n",
        "# Hidden Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Printing Structure\n",
        "for layer in model.layers:\n",
        "  print(str(layer.input_shape) + \" -> \" + str(layer.output_shape))\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "# Fitting\n",
        "opt = Adam(learning_rate = 0.01)\n",
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=200, epochs=5)\n",
        "\n",
        "# Evaluating\n",
        "print(\"\\n\\n\\n\")\n",
        "model.evaluate(x_train, y_train, verbose=0)\n",
        "model.evaluate(x_test, y_test, verbose=0)"
      ],
      "metadata": {
        "id": "1rlLZWrwpp6J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152b1ab2-a8a0-4ea1-c66d-f953746e4a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1) -> (None, 64)\n",
            "(None, 64) -> (None, 64, 128)\n",
            "(None, 64, 128) -> (None, 8192)\n",
            "(None, 8192) -> (None, 64)\n",
            "(None, 64) -> (None, 5)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/5\n",
            "82/82 [==============================] - 5s 44ms/step - loss: 0.9746 - accuracy: 0.5736\n",
            "Epoch 2/5\n",
            "82/82 [==============================] - 4s 44ms/step - loss: 0.4158 - accuracy: 0.8367\n",
            "Epoch 3/5\n",
            "82/82 [==============================] - 6s 78ms/step - loss: 0.1471 - accuracy: 0.9483\n",
            "Epoch 4/5\n",
            "82/82 [==============================] - 4s 49ms/step - loss: 0.0549 - accuracy: 0.9803\n",
            "Epoch 5/5\n",
            "82/82 [==============================] - 4s 43ms/step - loss: 0.0293 - accuracy: 0.9900\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.2103271484375, 0.5718467831611633]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##© 2024 The Coding School, All rights reserved"
      ],
      "metadata": {
        "id": "SZz2iPtzqdSB"
      }
    }
  ]
}