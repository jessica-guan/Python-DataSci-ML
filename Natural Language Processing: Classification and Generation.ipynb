{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessica-guan/Python-DataSci-ML/blob/main/Natural%20Language%20Processing%3A%20Classification%20and%20Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework 21: Natural Language Processing II**\n",
        "---\n",
        "\n",
        "### **Description**\n",
        "In this week's homework, you will see how to use more advanced forms of neural nets to perform tasks in NLP such as classification and generation.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Structure**\n",
        "**Part 1**: Sarcasm Detection in the News\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Cheat Sheets**\n",
        "[Natural Language Processing II](https://docs.google.com/document/d/1p3xVUL1F6SEkusCI4klPLYqQwCkVN5s00ZvJjBpiSqM/edit?usp=sharing)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Before starting, run the code below to import all necessary functions and libraries.**"
      ],
      "metadata": {
        "id": "dTIoQdGufbcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime\n",
        "\n",
        "from lime import lime_text\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from random import choices\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "yWd0JEE9fmrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81a3184-316b-4b3c-f399-72185b456d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Part 1: Sarcasm Detection in the News**\n",
        "---\n",
        "\n",
        "In this section, we will see how to apply what we learned yesterday in combination with more advanced tools to determine how sarcastic a given text is.\n",
        "\n",
        "<br>\n",
        "\n",
        "We will be working with a dataset containing the headline of many news articles and a classification of whether that headline is sarcastic or not.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "**Run the code provided below to import the dataset.**"
      ],
      "metadata": {
        "id": "iSkUvAmLfB78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vTHrKLcHxF-DSkeH5FMmpFm5KQzDbzdaCdj1aP89wmUVIg_TxLPaveVXt1C8kG2b3aLnuON6cqfABd5/pub?output=csv')\n",
        "data.head()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data[\"headline\"], data[\"is_sarcastic\"], test_size = 0.2, random_state = 42)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "wLXOcKuBfod0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Part 1.1:  Simple Deep Neural Networks**\n",
        "---\n",
        "\n",
        "In this section, you will use dense layers provided by keras to build a simple DNN."
      ],
      "metadata": {
        "id": "OgvzN47sq0oa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problem #1.1.1: Create the `TextVectorization` layer**\n",
        "\n",
        "\n",
        "To get started, let's create a `TextVectorization` layer to vectorize this data.\n",
        "\n",
        "Specifically,\n",
        "1. Initialize the layer with the specified parameters.\n",
        "\n",
        "2. Adapt the layer to the training data.\n",
        "\n",
        "3. Look at the newly built vocabulary."
      ],
      "metadata": {
        "id": "LTm3147qiKE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **1.Initialize the layer with the specified parameters.**\n",
        "\n",
        "* The vocabulary should be at most 2000 words.\n",
        "* The layer's output should always be 20 integers."
      ],
      "metadata": {
        "id": "d3zfKfgAiKE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens = 2000,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = 20\n",
        "  )"
      ],
      "metadata": {
        "id": "Lc6-HJGhiKE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **2. Adapt the layer to the training data.**"
      ],
      "metadata": {
        "id": "Bif_POk3iKE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.adapt(x_train)"
      ],
      "metadata": {
        "id": "bsnDnHGFiKE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **3. Look at the newly built vocabulary.**"
      ],
      "metadata": {
        "id": "ovHm-Icy2iZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.get_vocabulary()[:50]"
      ],
      "metadata": {
        "id": "bnAtuO3B2iZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9866d173-daf5-44d0-c8b0-46cab2dc5834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'to',\n",
              " 'of',\n",
              " 'the',\n",
              " 'in',\n",
              " 'for',\n",
              " 'a',\n",
              " 'on',\n",
              " 'and',\n",
              " 'with',\n",
              " 'is',\n",
              " 'new',\n",
              " 'trump',\n",
              " 'man',\n",
              " 'from',\n",
              " 'at',\n",
              " 'about',\n",
              " 'you',\n",
              " 'this',\n",
              " 'by',\n",
              " 'after',\n",
              " 'be',\n",
              " 'how',\n",
              " 'out',\n",
              " 'it',\n",
              " 'up',\n",
              " 'that',\n",
              " 'as',\n",
              " 'not',\n",
              " 'your',\n",
              " 'his',\n",
              " 'are',\n",
              " 'what',\n",
              " 'he',\n",
              " 'just',\n",
              " 'us',\n",
              " 'has',\n",
              " 'who',\n",
              " 'more',\n",
              " 'will',\n",
              " 'all',\n",
              " 'one',\n",
              " 'into',\n",
              " 'report',\n",
              " 'why',\n",
              " 'have',\n",
              " 'donald',\n",
              " 'area',\n",
              " 'over']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problem #1.1.2: Build the model**\n",
        "\n",
        "\n",
        "Complete the code below to build a model with the following layers.\n",
        "\n",
        "An `Embedding` layer such that:\n",
        "* The vocabulary contains 2000 tokens.\n",
        "* The input length corresponds to the output of the vectorization layer.\n",
        "* The number of outputs per input is 128.\n",
        "\n",
        "<br>\n",
        "\n",
        "Hidden layers:\n",
        "\n",
        "* A  `Flatten` layer.\n",
        "* A  `Dense` layer with 64 units (hidden states).\n",
        "\n",
        "<br>\n",
        "\n",
        "An output `Dense` layer. You can use activation `softmax`."
      ],
      "metadata": {
        "id": "_ULrKEoKiKE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Input, Vectorization, and Embedding Layers\n",
        "model.add(Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vectorize_layer)\n",
        "model.add(Embedding(input_dim=2000, output_dim=128))\n",
        "\n",
        "# Hidden Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "qliSJAYCiKE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problem #1.1.3: Compile and fit the model**\n",
        "\n",
        "\n",
        "Using standard parameters for classification, compile and train this neural network using:\n",
        "* A learning rate of 0.01.\n",
        "* A batch size of 200.\n",
        "* 5 epochs."
      ],
      "metadata": {
        "id": "RMhg0mcliKE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate = 0.01)\n",
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=200, epochs=5)"
      ],
      "metadata": {
        "id": "GIWQr3UFiKE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e764a3-c8db-4d1d-c110-6ee2f43f6c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "107/107 [==============================] - 9s 51ms/step - loss: 0.4167 - accuracy: 0.8050\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.2354 - accuracy: 0.9000\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 1s 11ms/step - loss: 0.1517 - accuracy: 0.9390\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.1053 - accuracy: 0.9568\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.0800 - accuracy: 0.9688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7975c45b1e40>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problem #1.1.4: Evaluate the model**\n",
        "\n",
        "\n",
        "Now, evaluate the model for both the training and test sets."
      ],
      "metadata": {
        "id": "rZDdIc2LiKE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training set\n",
        "train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"Training Loss:\", train_loss)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Test Loss:\", test_loss)"
      ],
      "metadata": {
        "id": "rtdeiWm7iKE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "665a460e-20c2-457a-f351-92287518fc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9813263416290283\n",
            "Training Loss: 0.05133132264018059\n",
            "Test Accuracy: 0.8161737322807312\n",
            "Test Loss: 0.8460763096809387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Part 1.2: Convolutional Neural Nets**\n",
        "---\n",
        "\n",
        "In this section, you will approach the same problem using the `Conv1D` and `MaxPooling1D` layers provided by keras."
      ],
      "metadata": {
        "id": "3D8iKE2U0eZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problem #1.2.1: Build a CNN**\n",
        "\n",
        "\n",
        "Complete the code below to build, *but not train*, a new CNN model. Specifically, create a model identical to the ones above except with hidden layers as follows:\n",
        "\n",
        "* A `Conv1D` layer with `filters = 1`, `kernel_size = 4`, and `activation = 'relu'`.\n",
        "* A `MaxPooling1D` layer with `pool_size = 2`."
      ],
      "metadata": {
        "id": "sKbPF8Z9LAWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Input, Vectorization, and Embedding Layers\n",
        "model.add(Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vectorize_layer)\n",
        "model.add(Embedding(input_dim=2000, output_dim=128))\n",
        "model.add(Conv1D(filters=1, kernel_size=4, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Hidden Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "S4_oXj-uLAWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problem #1.2.2: Examine the CNN's structure**\n",
        "\n",
        "\n",
        "Now, let's look at the structure of this neural network.\n",
        "\n",
        "**Run the code below to print the input and output shapes of each layer.**"
      ],
      "metadata": {
        "id": "QFEo-5xuVk2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  print(str(layer.input_shape) + \" -> \" + str(layer.output_shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtSHQoz0Vv2t",
        "outputId": "169f3cab-8328-4770-faec-8bb7155c2ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1) -> (None, 20)\n",
            "(None, 20) -> (None, 20, 128)\n",
            "(None, 20, 128) -> (None, 17, 1)\n",
            "(None, 17, 1) -> (None, 8, 1)\n",
            "(None, 8, 1) -> (None, 8)\n",
            "(None, 8) -> (None, 64)\n",
            "(None, 64) -> (None, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problem #1.2.3: Train and Evaluate the CNN**\n",
        "\n",
        "\n",
        "Now, complete the code below to train and evaluate this model."
      ],
      "metadata": {
        "id": "ZjQMsF11VyHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting\n",
        "opt = Adam(learning_rate = 0.01)\n",
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=200, epochs=5)\n",
        "\n",
        "\n",
        "# Evaluating\n",
        "print(\"\\n\\n\\n\")\n",
        "model.evaluate(x_train, y_train, verbose=0)\n",
        "model.evaluate(x_test, y_test, verbose=0)"
      ],
      "metadata": {
        "id": "9H-BY04zV5BG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "111f4557-0f75-4dda-e228-5e7dd2371d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "107/107 [==============================] - 8s 61ms/step - loss: 0.3063 - accuracy: 0.8724\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.1616 - accuracy: 0.9348\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 1s 14ms/step - loss: 0.1125 - accuracy: 0.9561\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 1s 10ms/step - loss: 0.0885 - accuracy: 0.9671\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 1s 6ms/step - loss: 0.0715 - accuracy: 0.9729\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7122322916984558, 0.8178584575653076]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problem #1.2.4: Adjust the model**\n",
        "\n",
        "\n",
        "Complete the code below to train a new CNN model. Specifically, create a model identical to the ones above except with hidden layers as follows:\n",
        "\n",
        "* A `Conv1D` layer with `filters = 64`, `kernel_size = 3`, and `activation = 'relu'`.\n",
        "* A `MaxPooling1D` layer with `pool_size = 2`."
      ],
      "metadata": {
        "id": "aCfKk9hkPB2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Input, Vectorization, and Embedding Layers\n",
        "model.add(Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vectorize_layer)\n",
        "model.add(Embedding(input_dim=2000, output_dim=128))\n",
        "model.add(Conv1D(filters=63, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Hidden Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "# Printing Structure\n",
        "for layer in model.layers:\n",
        "  print(str(layer.input_shape) + \" -> \" + str(layer.output_shape))\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "\n",
        "# Fitting\n",
        "opt = Adam(learning_rate = 0.01)\n",
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=200, epochs=5)\n",
        "\n",
        "\n",
        "# Evaluating\n",
        "print(\"\\n\\n\\n\")\n",
        "model.evaluate(x_train, y_train, verbose=0)\n",
        "model.evaluate(x_test, y_test, verbose=0)"
      ],
      "metadata": {
        "id": "G9LN8miLPB2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ccc4be-f02e-4b65-efbe-f014e6ca2e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1) -> (None, 20)\n",
            "(None, 20) -> (None, 20, 128)\n",
            "(None, 20, 128) -> (None, 18, 63)\n",
            "(None, 18, 63) -> (None, 9, 63)\n",
            "(None, 9, 63) -> (None, 567)\n",
            "(None, 567) -> (None, 64)\n",
            "(None, 64) -> (None, 2)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 8s 60ms/step - loss: 0.4003 - accuracy: 0.8078\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 2s 21ms/step - loss: 0.2631 - accuracy: 0.8865\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 2s 17ms/step - loss: 0.1853 - accuracy: 0.9243\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.1322 - accuracy: 0.9493\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.0978 - accuracy: 0.9627\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6236959099769592, 0.828528642654419]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problem #1.2.5: Improve the model**\n",
        "---\n",
        "\n",
        "You are likely seeing that this last model performs better on the test set than most others you have seen today. It will be challenging to beat this; however, see if you can improve the model any more by adjusting any parameters including:\n",
        "\n",
        "* **Number of filters**: Can we get away with fewer filters? Should we add more filters?\n",
        "* **Kernel size**: What happens when we change this more significantly?\n",
        "* **Pool size**: Should we be pooling more inputs together or fewer?\n",
        "* **Dense layers**: Would adding any dense layers after the convolved results are pooled and flatten help?\n",
        "* **Number of convolutional and pooling layers**: If you're careful about the input and output shapes, it is possible to stack multiple convolutional and pooling layers.\n",
        "* **Training parameters**: Would it help to adjust the learning rate, number of epochs, or batch size?"
      ],
      "metadata": {
        "id": "2unPUULPWy_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Input, Vectorization, and Embedding Layers\n",
        "model.add(Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vectorize_layer)\n",
        "model.add(Embedding(input_dim=2000, output_dim=128))\n",
        "model.add(Conv1D(filters=63, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Hidden Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "# Printing Structure\n",
        "for layer in model.layers:\n",
        "  print(str(layer.input_shape) + \" -> \" + str(layer.output_shape))\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "\n",
        "# Fitting\n",
        "opt = Adam(learning_rate = 0.01)\n",
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=200, epochs=5)\n",
        "\n",
        "\n",
        "# Evaluating\n",
        "print(\"\\n\\n\\n\")\n",
        "model.evaluate(x_train, y_train, verbose=0)\n",
        "model.evaluate(x_test, y_test, verbose=0)"
      ],
      "metadata": {
        "id": "UAbzdj1dWy_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5af6744-b6f7-481a-adf1-8d0a839cda39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1) -> (None, 20)\n",
            "(None, 20) -> (None, 20, 128)\n",
            "(None, 20, 128) -> (None, 18, 63)\n",
            "(None, 18, 63) -> (None, 9, 63)\n",
            "(None, 9, 63) -> (None, 567)\n",
            "(None, 567) -> (None, 64)\n",
            "(None, 64) -> (None, 2)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 8s 61ms/step - loss: 0.4076 - accuracy: 0.8028\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 2s 18ms/step - loss: 0.2587 - accuracy: 0.8928\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 2s 15ms/step - loss: 0.1820 - accuracy: 0.9260\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.1308 - accuracy: 0.9489\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 1s 9ms/step - loss: 0.0960 - accuracy: 0.9640\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6140491366386414, 0.8294646143913269]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dzC09dLlEhm"
      },
      "source": [
        "---\n",
        "#End of notebook\n",
        "\n",
        "© 2024 The Coding School, All rights reserved"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}